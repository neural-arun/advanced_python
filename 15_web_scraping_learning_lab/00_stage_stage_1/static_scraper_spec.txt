ğŸ”¥ **THIS IS A VERY STRONG MOVE.**
Tum basically apna **â€œScraper Spec Engineâ€** bana rahe ho â€”
jisse **Chrome â†’ Spec â†’ AI â†’ Production Scraper** ka pipeline ban jaata hai.

Neeche main tumhe **exactly wahi cheez** de raha hoon jo tumne maangi:

* âœ… **Ek fill-in template (TXT file)**
* âœ… Chrome inspection ke according fill karoge
* âœ… AI ko doge
* âœ… AI tumhe **clean, class-based, production-ready static scraper** de dega

Isko tum literally `static_scraper_spec.txt` ke naam se save kar sakte ho.

---

# ğŸ“„ `static_scraper_spec.txt`

## **UNIVERSAL STATIC WEBSITE SCRAPER SPEC (FILL & USE)**

---

## ğŸ”¹ SECTION 1: WEBSITE BASICS

```
WEBSITE_NAME:
WEBSITE_URL (base/start page):
IS_WEBSITE_STATIC (yes/no):
(How you confirmed: HTML contains data / no XHR needed)
```

---

## ğŸ”¹ SECTION 2: REQUEST / IDENTITY

```
NEEDS_HEADERS (yes/no):
If yes, list headers:

User-Agent:
Accept-Language:
Other headers (if any):

Does the site block without headers? (yes/no)
```

---

## ğŸ”¹ SECTION 3: RECORD IDENTIFICATION (MOST IMPORTANT)

```
WHAT IS ONE RECORD?
(e.g. one product / one book / one quote)

PARENT_TAG:
PARENT_CLASS (or id):

How you confirmed parent:
(hover highlights full record / repeats on page)
```

---

## ğŸ”¹ SECTION 4: DATA FIELDS TO EXTRACT

### FIELD 1

```
FIELD_NAME:
TAG:
CLASS / ID:
IS_TEXT_OR_ATTRIBUTE (text / attribute):
If attribute, attribute name:
Any cleaning needed? (strip, replace, map)
```

### FIELD 2

```
FIELD_NAME:
TAG:
CLASS / ID:
IS_TEXT_OR_ATTRIBUTE (text / attribute):
If attribute, attribute name:
Any cleaning needed?
```

### FIELD 3

```
FIELD_NAME:
TAG:
CLASS / ID:
IS_TEXT_OR_ATTRIBUTE (text / attribute):
If attribute, attribute name:
Any cleaning needed?
```

(Add more fields as needed)

---

## ğŸ”¹ SECTION 5: SPECIAL DATA LOGIC (IMPORTANT)

```
Is any data encoded in class names? (yes/no)
If yes:
- Which field:
- Example class list:
- How to extract actual value:

Is any field sometimes missing? (yes/no)
Which field(s):
```

---

## ğŸ”¹ SECTION 6: PAGINATION / FLOW

```
IS_PAGINATION_PRESENT (yes/no):

If yes:
NEXT_BUTTON_TAG:
NEXT_BUTTON_CLASS:

LINK_TYPE:
(relative / absolute)

EXAMPLE_NEXT_LINK (from HTML):

STOP_CONDITION:
(next button missing / disabled / page number limit)
```

---

## ğŸ”¹ SECTION 7: OUTPUT REQUIREMENTS

```
OUTPUT_FORMAT:
(json / csv / print only)

FILE_NAME (if saving):

Should data be returned as list of dicts? (yes/no)
```

---

## ğŸ”¹ SECTION 8: ENGINEERING PREFERENCES

```
USE_SCRAPER_CLASS (yes/no): yes
METHODS_EXPECTED:
(fetch_html, parse_html, extract_records, paginate, save_output)

USE_TYPE_HINTS (yes/no):
USE_PYDANTIC (yes/no):
ERROR_HANDLING_LEVEL:
(basic / safe skip / strict fail)

Any performance concerns? (low / medium / high)
```

---

## ğŸ”¹ SECTION 9: FINAL INSTRUCTION TO AI (DO NOT EDIT)

```
TASK FOR AI:

Using the above specification, generate a clean, 
production-quality Python scraper for a STATIC website.

Requirements:
- Use requests + BeautifulSoup
- Use a Scraper class
- Follow separation of concerns:
  network / parser / extractor / flow / output
- Handle missing data safely
- Do NOT over-engineer
- Add comments explaining logic
```

---

# ğŸ§  HOW YOU WILL USE THIS (IMPORTANT)

### Step 1ï¸âƒ£

Chrome â†’ Inspect website â†’ fill this TXT file

### Step 2ï¸âƒ£

Paste the filled TXT into AI and say:

> â€œGenerate scraper using this spec. Follow it strictly.â€

### Step 3ï¸âƒ£

AI gives you:

* Clean class-based scraper
* You review logic
* You tweak selectors if needed

ğŸ‘‰ **This is modern scraping workflow.**
